{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea206360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IST769 Midterm\n",
    "#-----------------\n",
    "\n",
    "# You will turn this file in along with screenshots as instructed on Blackboard\n",
    "\n",
    "# YOUR NAME: Saiteja Namani\n",
    "# YOUR EMAIL: snamani@syr.edu\n",
    "# YOUR SUID: 7819937922"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3254652-59ff-490d-9e2d-00d9d77e2baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "user = \"minio\"\n",
    "passwd = \"SU2orange!\"\n",
    "s3_bucket = \"gamestreams\"\n",
    "s3_server = \"http://minio:9000\"\n",
    "s3_access_key = user\n",
    "s3_secret_key = passwd\n",
    "mongo_uri = f\"mongodb://mongo:{passwd}@mongo:27017/admin?authSource=admin\"\n",
    "server_name = \"jdbc:sqlserver://mssql\"\n",
    "database_name = \"sidearmdb\"\n",
    "mssql_user = \"sa\"\n",
    "mssql_pw = passwd\n",
    "mssql_url = server_name + \";\" + \"databaseName=\" + database_name + \";encrypt=true;trustServerCertificate=true;\"\n",
    "\n",
    "jars = [\n",
    "    \"org.apache.hadoop:hadoop-aws:3.1.2\",\n",
    "    \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\",\n",
    "    \"com.microsoft.azure:spark-mssql-connector_2.12:1.2.0\",\n",
    "    \"com.microsoft.sqlserver:mssql-jdbc:12.2.0.jre11\"\n",
    "]\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "        .config(\"spark.jars.packages\",\",\".join(jars) )\\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", s3_server ) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", s3_access_key) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", s3_secret_key) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.fast.upload\", True) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", True) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.mongodb.input.uri\", mongo_uri) \\\n",
    "        .config(\"spark.mongodb.output.uri\", mongo_uri) \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\") # Keeps the noise down!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d93a740-0b7c-410f-a8ed-2ad5734c34c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-----+-----+------+\n",
      "| id|  name|number|shots|goals|teamid|\n",
      "+---+------+------+-----+-----+------+\n",
      "|  1|   sam|     6|   56|   23|   101|\n",
      "|  2| sarah|     1|   85|   34|   101|\n",
      "|  3| steve|     2|   60|   20|   101|\n",
      "|  4| stone|    13|   33|   10|   101|\n",
      "|  5|  sean|    17|   26|    9|   101|\n",
      "|  6|   sly|     8|   78|   15|   101|\n",
      "|  7|   sol|     9|   52|   20|   101|\n",
      "|  8| shree|     4|   20|    4|   101|\n",
      "|  9|shelly|    15|   10|    2|   101|\n",
      "| 10| swede|    10|   90|   50|   101|\n",
      "| 11| jimmy|     1|  100|   50|   205|\n",
      "| 12| julie|     9|   10|    0|   205|\n",
      "| 13| james|     2|   45|   15|   205|\n",
      "| 14|  jane|    15|   82|   46|   205|\n",
      "| 15| jimmy|    16|   42|   30|   205|\n",
      "| 16| julie|     8|   67|   32|   205|\n",
      "| 17| james|    17|   40|   14|   205|\n",
      "| 18|  jane|     3|   91|   40|   205|\n",
      "| 19| jimmy|     5|   78|   22|   205|\n",
      "| 20| julie|    22|   83|   19|   205|\n",
      "+---+------+------+-----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HOW TO READ FROM MSSQL\n",
    "df = spark.read.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"players\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .load()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2486f5fd-62fe-41c7-b042-53098cb6da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW TO WRITE TO MSSQL\n",
    "df.write.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"players2\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "60bb340d-d6db-419e-9eb2-55f53f079cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|            value|\n",
      "+-----------------+\n",
      "|  0 59:51 101 2 0|\n",
      "|  1 57:06 101 6 0|\n",
      "|  2 56:13 205 8 1|\n",
      "|  3 55:25 101 4 0|\n",
      "|  4 55:03 101 1 1|\n",
      "| 5 54:50 101 17 0|\n",
      "|  6 54:14 205 8 0|\n",
      "|  7 53:59 101 9 0|\n",
      "|  8 53:23 101 2 0|\n",
      "| 9 51:21 101 13 0|\n",
      "| 10 49:55 101 1 1|\n",
      "| 11 49:28 101 2 1|\n",
      "|12 48:52 101 10 1|\n",
      "| 13 47:52 101 4 1|\n",
      "| 14 47:44 101 9 0|\n",
      "| 15 46:38 101 2 0|\n",
      "| 16 45:49 101 1 1|\n",
      "| 17 45:31 101 4 0|\n",
      "| 18 43:29 205 1 1|\n",
      "| 19 41:54 205 1 1|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Read the gamestream.txt from minio\n",
    "\n",
    "df_min = spark.read.text(\"s3a://gamestreams/gamestream.txt\")\n",
    "df_min.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb788d2f-d58f-4d42-bc40-124facbb8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Write the gamestream to mongodb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3565b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWERS TO EXAM QUESTIONS\n",
    "# PLACE YOUR ANSWERS BELOW TURN THIS .ipynb FILE IN ALONG WITH SCREENSHOTS AS INSTRUCTED ON BLACKBOARD"
   ]
  },
  {
   "cell_type": "raw",
   "id": "865fc4d9-cd70-4ed4-a6d2-4d1d5451a3e7",
   "metadata": {},
   "source": [
    "# Q1 \n",
    "SELECT\n",
    "    teamData.name AS team_name,\n",
    "    teamData.wins AS team_wins,\n",
    "    teamData.losses AS team_losses,\n",
    "    playerStats.name AS player_name,\n",
    "    playerStats.shots AS player_shots,\n",
    "    playerStats.goals AS player_goals\n",
    "FROM\n",
    "    mssql.`teams` AS teamData\n",
    "INNER JOIN\n",
    "    mssql.`players` AS playerStats ON teamData.id = playerStats.teamid;"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d80e70ac-c353-4502-88b7-89b2900c64e0",
   "metadata": {},
   "source": [
    "# Q2\n",
    "SELECT\n",
    "    columns[0] AS team_ID,\n",
    "    columns[1] AS jersey_number,\n",
    "    columns[2] AS shots,\n",
    "    columns[3] AS goals,\n",
    "    columns[4] AS team_goals\n",
    "FROM\n",
    "    minio.`gamestream.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35cf344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------+-------------+-----+\n",
      "|event_id|timestamp|team_ID|jersey_number|goals|\n",
      "+--------+---------+-------+-------------+-----+\n",
      "|       0|    59:51|    101|            2|    0|\n",
      "|       1|    57:06|    101|            6|    0|\n",
      "|       2|    56:13|    205|            8|    1|\n",
      "|       3|    55:25|    101|            4|    0|\n",
      "|       4|    55:03|    101|            1|    1|\n",
      "|       5|    54:50|    101|           17|    0|\n",
      "|       6|    54:14|    205|            8|    0|\n",
      "|       7|    53:59|    101|            9|    0|\n",
      "|       8|    53:23|    101|            2|    0|\n",
      "|       9|    51:21|    101|           13|    0|\n",
      "|      10|    49:55|    101|            1|    1|\n",
      "|      11|    49:28|    101|            2|    1|\n",
      "|      12|    48:52|    101|           10|    1|\n",
      "|      13|    47:52|    101|            4|    1|\n",
      "|      14|    47:44|    101|            9|    0|\n",
      "|      15|    46:38|    101|            2|    0|\n",
      "|      16|    45:49|    101|            1|    1|\n",
      "|      17|    45:31|    101|            4|    0|\n",
      "|      18|    43:29|    205|            1|    1|\n",
      "|      19|    41:54|    205|            1|    1|\n",
      "|      20|    41:09|    101|            1|    1|\n",
      "|      21|    41:03|    205|            5|    1|\n",
      "|      22|    41:02|    101|           13|    0|\n",
      "|      23|    40:47|    101|           15|    0|\n",
      "|      24|    40:20|    101|            1|    1|\n",
      "|      25|    39:09|    101|            9|    0|\n",
      "|      26|    38:06|    101|            4|    0|\n",
      "|      27|    38:03|    101|           13|    1|\n",
      "|      28|    37:48|    205|           15|    1|\n",
      "|      29|    37:31|    205|           15|    1|\n",
      "|      30|    37:02|    101|           15|    0|\n",
      "|      31|    36:31|    205|            2|    0|\n",
      "|      32|    34:33|    101|            2|    0|\n",
      "|      33|    34:22|    101|           15|    1|\n",
      "|      34|    33:15|    101|            4|    0|\n",
      "|      35|    32:23|    205|            9|    0|\n",
      "|      36|    31:38|    101|            8|    0|\n",
      "|      37|    30:45|    101|            6|    0|\n",
      "|      38|    30:31|    101|           10|    0|\n",
      "|      39|    30:26|    101|           13|    0|\n",
      "|      40|    30:07|    101|            8|    0|\n",
      "|      41|    29:04|    205|           17|    0|\n",
      "|      42|    27:56|    205|           16|    0|\n",
      "|      43|    25:56|    205|           22|    0|\n",
      "|      44|    25:26|    205|            2|    0|\n",
      "|      45|    25:20|    205|            9|    0|\n",
      "|      46|    25:17|    101|           13|    0|\n",
      "|      47|    24:57|    101|            6|    1|\n",
      "|      48|    23:57|    101|            6|    1|\n",
      "|      49|    22:36|    205|            9|    0|\n",
      "|      50|    20:48|    205|           17|    0|\n",
      "|      51|    20:43|    205|            9|    0|\n",
      "|      52|    20:22|    101|            1|    1|\n",
      "|      53|    19:04|    205|            3|    0|\n",
      "|      54|    18:24|    101|            1|    0|\n",
      "|      55|    17:23|    205|            1|    1|\n",
      "|      56|    15:29|    101|            9|    0|\n",
      "|      57|    13:18|    101|            8|    0|\n",
      "|      58|    13:12|    101|           10|    0|\n",
      "|      59|    13:07|    205|            2|    1|\n",
      "|      60|    12:32|    205|           17|    1|\n",
      "|      61|    11:33|    101|            2|    0|\n",
      "+--------+---------+-------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q3\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as func\n",
    "\n",
    "split_cols = func.split(df_min['value'],' ')\n",
    "\n",
    "df_label = df_min \\\n",
    "    .withColumn('event_id', split_cols.getItem(0).cast('int')) \\\n",
    "    .withColumn('timestamp', split_cols.getItem(1)) \\\n",
    "    .withColumn('team_ID', split_cols.getItem(2).cast('int')) \\\n",
    "    .withColumn('jersey_number', split_cols.getItem(3).cast('int')) \\\n",
    "    .withColumn('goals', split_cols.getItem(4).cast('int'))\n",
    "\n",
    "df_2 = df_label.drop('value')\n",
    "\n",
    "df_2.write.format(\"mongo\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"database\", \"sidearm\") \\\n",
    "    .option(\"collection\", \"boxscores\") \\\n",
    "    .save()\n",
    "\n",
    "df_2.show(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ea5d68ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 366:===================================>                 (134 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----+-----+----------+\n",
      "|team_ID|jersey_number|shots|goals|team_goals|\n",
      "+-------+-------------+-----+-----+----------+\n",
      "|    101|            1|    7|    6|        13|\n",
      "|    101|            2|    6|    1|        13|\n",
      "|    101|            4|    5|    1|        13|\n",
      "|    101|            6|    4|    2|        13|\n",
      "|    101|            8|    3|    0|        13|\n",
      "|    101|            9|    4|    0|        13|\n",
      "|    101|           10|    3|    1|        13|\n",
      "|    101|           13|    5|    1|        13|\n",
      "|    101|           15|    3|    1|        13|\n",
      "|    101|           17|    1|    0|        13|\n",
      "|    205|            1|    3|    3|         9|\n",
      "|    205|            2|    3|    1|         9|\n",
      "|    205|            3|    1|    0|         9|\n",
      "|    205|            5|    1|    1|         9|\n",
      "|    205|            8|    2|    1|         9|\n",
      "|    205|            9|    4|    0|         9|\n",
      "|    205|           15|    2|    2|         9|\n",
      "|    205|           16|    1|    0|         9|\n",
      "|    205|           17|    3|    1|         9|\n",
      "|    205|           22|    1|    0|         9|\n",
      "+-------+-------------+-----+-----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Q4\n",
    "\n",
    "df_2.createOrReplaceTempView(\"gamestream\")\n",
    "\n",
    "sql_query = \"\"\"\n",
    "\n",
    "SELECT gs.team_ID, gs.jersey_number, COUNT(*) AS shots, SUM(gs.goals) AS goals, tg.team_goals\n",
    "FROM gamestream gs\n",
    "JOIN\n",
    "    (SELECT team_ID, SUM(goals) AS team_goals\n",
    "         FROM gamestream\n",
    "         WHERE team_ID > 0\n",
    "     GROUP BY team_ID) \n",
    "tg ON gs.team_ID = tg.team_ID\n",
    "\n",
    "WHERE gs.team_ID > 0\n",
    "GROUP BY gs.team_ID, gs.jersey_number, tg.team_goals\n",
    "ORDER BY gs.team_ID, gs.jersey_number\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(sql_query)\n",
    "\n",
    "result.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53e53863-800d-4f67-a47e-7ee4ae60b6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 372:==========================================>          (160 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----+-----+----------+--------------+----------------+\n",
      "|team_ID|jersey_number|shots|goals|team_goals|latest_eventid|latest_timestamp|\n",
      "+-------+-------------+-----+-----+----------+--------------+----------------+\n",
      "|    101|            1|    7|    6|        13|            61|           59:51|\n",
      "|    101|            2|    6|    1|        13|            61|           59:51|\n",
      "|    101|            4|    5|    1|        13|            61|           59:51|\n",
      "|    101|            6|    4|    2|        13|            61|           59:51|\n",
      "|    101|            8|    3|    0|        13|            61|           59:51|\n",
      "|    101|            9|    4|    0|        13|            61|           59:51|\n",
      "|    101|           10|    3|    1|        13|            61|           59:51|\n",
      "|    101|           13|    5|    1|        13|            61|           59:51|\n",
      "|    101|           15|    3|    1|        13|            61|           59:51|\n",
      "|    101|           17|    1|    0|        13|            61|           59:51|\n",
      "|    205|            1|    3|    3|         9|            61|           59:51|\n",
      "|    205|            2|    3|    1|         9|            61|           59:51|\n",
      "|    205|            3|    1|    0|         9|            61|           59:51|\n",
      "|    205|            5|    1|    1|         9|            61|           59:51|\n",
      "|    205|            8|    2|    1|         9|            61|           59:51|\n",
      "|    205|            9|    4|    0|         9|            61|           59:51|\n",
      "|    205|           15|    2|    2|         9|            61|           59:51|\n",
      "|    205|           16|    1|    0|         9|            61|           59:51|\n",
      "|    205|           17|    3|    1|         9|            61|           59:51|\n",
      "|    205|           22|    1|    0|         9|            61|           59:51|\n",
      "+-------+-------------+-----+-----+----------+--------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Q5\n",
    "\n",
    "from pyspark.sql import functions as func\n",
    "\n",
    "df_2.createOrReplaceTempView(\"gamestream\")\n",
    "\n",
    "latest_event_and_timestamp = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        MAX(event_id) AS latest_eventid, \n",
    "        MAX(timestamp) AS latest_timestamp\n",
    "    FROM gamestream\n",
    "    WHERE team_ID != 0\n",
    "\"\"\").collect()[0]\n",
    "\n",
    "latest_eventid = latest_event_and_timestamp['latest_eventid']\n",
    "latest_timestamp = latest_event_and_timestamp['latest_timestamp']\n",
    "\n",
    "result_2 = result.withColumn(\"latest_eventid\", func.lit(latest_eventid))\\\n",
    "                     .withColumn(\"latest_timestamp\", func.lit(latest_timestamp))\n",
    "\n",
    "result_2.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8cc24d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----+-----+----------+-----------+-------------+----------+----+------+\n",
      "|team_ID|jersey_number|shots|goals|team_goals|player_name|    team_name|conference|wins|losses|\n",
      "+-------+-------------+-----+-----+----------+-----------+-------------+----------+----+------+\n",
      "|    101|            9|    4|    0|        13|        sol|     syracuse|       acc|  11|     2|\n",
      "|    101|           10|    3|    1|        13|      swede|     syracuse|       acc|  11|     2|\n",
      "|    101|            2|    6|    1|        13|      steve|     syracuse|       acc|  11|     2|\n",
      "|    101|            8|    3|    0|        13|        sly|     syracuse|       acc|  11|     2|\n",
      "|    101|           13|    5|    1|        13|      stone|     syracuse|       acc|  11|     2|\n",
      "|    101|            6|    4|    2|        13|        sam|     syracuse|       acc|  11|     2|\n",
      "|    101|           15|    3|    1|        13|     shelly|     syracuse|       acc|  11|     2|\n",
      "|    101|            1|    7|    6|        13|      sarah|     syracuse|       acc|  11|     2|\n",
      "|    101|            4|    5|    1|        13|      shree|     syracuse|       acc|  11|     2|\n",
      "|    101|           17|    1|    0|        13|       sean|     syracuse|       acc|  11|     2|\n",
      "|    205|            9|    4|    0|         9|      julie|johns hopkins|     big10|   9|     4|\n",
      "|    205|            2|    3|    1|         9|      james|johns hopkins|     big10|   9|     4|\n",
      "|    205|           16|    1|    0|         9|      jimmy|johns hopkins|     big10|   9|     4|\n",
      "|    205|            3|    1|    0|         9|       jane|johns hopkins|     big10|   9|     4|\n",
      "|    205|           15|    2|    2|         9|       jane|johns hopkins|     big10|   9|     4|\n",
      "|    205|            5|    1|    1|         9|      jimmy|johns hopkins|     big10|   9|     4|\n",
      "|    205|            1|    3|    3|         9|      jimmy|johns hopkins|     big10|   9|     4|\n",
      "|    205|           22|    1|    0|         9|      julie|johns hopkins|     big10|   9|     4|\n",
      "|    205|           17|    3|    1|         9|      james|johns hopkins|     big10|   9|     4|\n",
      "|    205|            8|    2|    1|         9|      julie|johns hopkins|     big10|   9|     4|\n",
      "+-------+-------------+-----+-----+----------+-----------+-------------+----------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q6\n",
    "players_df = spark.read.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"players\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .load()\n",
    "\n",
    "teams_df = spark.read.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"teams\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .load()\n",
    "\n",
    "result.createOrReplaceTempView(\"result\")\n",
    "players_df.createOrReplaceTempView(\"players\")\n",
    "teams_df.createOrReplaceTempView(\"teams\")\n",
    "\n",
    "df_3 = spark.sql(\"\"\"\n",
    "SELECT r.*, p.name as player_name, t.name as team_name, t.conference, t.wins, t.losses\n",
    "FROM result r\n",
    "LEFT JOIN players p ON p.teamid = r.team_ID AND r.jersey_number = p.number\n",
    "LEFT JOIN teams t ON r.team_ID = t.id\n",
    "\"\"\")\n",
    "\n",
    "df_3.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80d9a966-d72d-42af-bd8f-2748973f79ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 505:================================================>    (183 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 61, 'timestamp': '59:51', 'home': {'team_ID': 101, 'conference': 'acc', 'wins': 11, 'losses': 2, 'score': 14, 'players': [{'jersey_number': 9, 'player_name': 'sol', 'shots': 4, 'goals': 0, 'pct': 0.0}, {'jersey_number': 10, 'player_name': 'swede', 'shots': 3, 'goals': 1, 'pct': 0.3333333333333333}, {'jersey_number': 2, 'player_name': 'steve', 'shots': 7, 'goals': 2, 'pct': 0.2857142857142857}, {'jersey_number': 8, 'player_name': 'sly', 'shots': 3, 'goals': 0, 'pct': 0.0}, {'jersey_number': 13, 'player_name': 'stone', 'shots': 5, 'goals': 1, 'pct': 0.2}, {'jersey_number': 6, 'player_name': 'sam', 'shots': 4, 'goals': 2, 'pct': 0.5}, {'jersey_number': 15, 'player_name': 'shelly', 'shots': 3, 'goals': 1, 'pct': 0.3333333333333333}, {'jersey_number': 1, 'player_name': 'sarah', 'shots': 7, 'goals': 6, 'pct': 0.8571428571428571}, {'jersey_number': 4, 'player_name': 'shree', 'shots': 5, 'goals': 1, 'pct': 0.2}, {'jersey_number': 17, 'player_name': 'sean', 'shots': 1, 'goals': 0, 'pct': 0.0}], 'status': 'tied'}, 'away': {'team_ID': 205, 'conference': 'big10', 'wins': 9, 'losses': 4, 'score': 9, 'players': [{'jersey_number': 9, 'player_name': 'julie', 'shots': 4, 'goals': 0, 'pct': 0.0}, {'jersey_number': 2, 'player_name': 'james', 'shots': 3, 'goals': 1, 'pct': 0.3333333333333333}, {'jersey_number': 16, 'player_name': 'jimmy', 'shots': 1, 'goals': 0, 'pct': 0.0}, {'jersey_number': 3, 'player_name': 'jane', 'shots': 1, 'goals': 0, 'pct': 0.0}, {'jersey_number': 15, 'player_name': 'jane', 'shots': 2, 'goals': 2, 'pct': 1.0}, {'jersey_number': 5, 'player_name': 'jimmy', 'shots': 1, 'goals': 1, 'pct': 1.0}, {'jersey_number': 1, 'player_name': 'jimmy', 'shots': 3, 'goals': 3, 'pct': 1.0}, {'jersey_number': 22, 'player_name': 'julie', 'shots': 1, 'goals': 0, 'pct': 0.0}, {'jersey_number': 17, 'player_name': 'james', 'shots': 3, 'goals': 1, 'pct': 0.3333333333333333}, {'jersey_number': 8, 'player_name': 'julie', 'shots': 2, 'goals': 1, 'pct': 0.5}], 'status': 'losing'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Q7\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "team_stats_agg = df_3.groupBy(\"team_ID\").agg(\n",
    "    F.first(\"conference\").alias(\"conference\"),\n",
    "    F.first(\"wins\").alias(\"wins\"),\n",
    "    F.first(\"losses\").alias(\"losses\"),\n",
    "    F.sum(\"goals\").alias(\"score\"),\n",
    "    F.collect_list(\n",
    "        F.struct(\n",
    "            \"jersey_number\", \n",
    "            \"player_name\", \n",
    "            \"shots\", \n",
    "            \"goals\",\n",
    "            F.when(F.col(\"shots\") > 0, F.col(\"goals\") / F.col(\"shots\")).otherwise(F.lit(0)).alias(\"pct\")\n",
    "        )\n",
    "    ).alias(\"players\")\n",
    ")\n",
    "\n",
    "\n",
    "windowSpec = Window.partitionBy()\n",
    "team_stats_agg = team_stats_agg.withColumn(\"max_score\", F.max(\"score\").over(windowSpec))\n",
    "\n",
    "\n",
    "team_stats_agg = team_stats_agg.withColumn(\n",
    "    \"status\",\n",
    "    F.when(F.col(\"score\") == F.col(\"max_score\"), \"tied\").otherwise(\n",
    "        F.when(F.col(\"score\") < F.col(\"max_score\"), \"losing\").otherwise(\"winning\")\n",
    "    )\n",
    ").drop(\"max_score\")\n",
    "\n",
    "\n",
    "home_team_stats = team_stats_agg.filter(F.col(\"team_ID\") == 101)\n",
    "away_team_stats = team_stats_agg.filter(F.col(\"team_ID\") == 205)\n",
    "\n",
    " \n",
    "home_json = home_team_stats.toJSON().first()\n",
    "away_json = away_team_stats.toJSON().first()\n",
    "\n",
    "import json\n",
    "\n",
    "home_dict = json.loads(home_json)\n",
    "away_dict = json.loads(away_json)\n",
    "\n",
    "\n",
    "box_score_document = {\n",
    "    \"_id\": latest_eventid,\n",
    "    \"timestamp\": latest_timestamp,\n",
    "    \"home\": home_dict,\n",
    "    \"away\": away_dict\n",
    "}\n",
    "\n",
    "print(box_score_document) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff5f9330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8\n",
    "import json\n",
    "\n",
    "json_boxscore = json.dumps(box_score_document)\n",
    "df_boxscores = spark.read.json(spark.sparkContext.parallelize([box_score_json]))\n",
    "\n",
    "df_boxscores.write.format(\"mongo\") \\\n",
    "    .option(\"database\", \"sidearm\") \\\n",
    "    .option(\"collection\", \"boxscores\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10472e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 62, 'timestamp': '59:51', 'home': {'team_ID': 101, 'conference': 'acc', 'wins': 11, 'losses': 2, 'score': 14, 'players': [{'jersey_number': 9, 'player_name': 'sol', 'shots': 4, 'goals': 0, 'pct': 0.0}, {'jersey_number': 10, 'player_name': 'swede', 'shots': 3, 'goals': 1, 'pct': 0.3333333333333333}, {'jersey_number': 2, 'player_name': 'steve', 'shots': 7, 'goals': 2, 'pct': 0.2857142857142857}, {'jersey_number': 8, 'player_name': 'sly', 'shots': 3, 'goals': 0, 'pct': 0.0}, {'jersey_number': 13, 'player_name': 'stone', 'shots': 5, 'goals': 1, 'pct': 0.2}, {'jersey_number': 6, 'player_name': 'sam', 'shots': 4, 'goals': 2, 'pct': 0.5}, {'jersey_number': 15, 'player_name': 'shelly', 'shots': 3, 'goals': 1, 'pct': 0.3333333333333333}, {'jersey_number': 1, 'player_name': 'sarah', 'shots': 7, 'goals': 6, 'pct': 0.8571428571428571}, {'jersey_number': 4, 'player_name': 'shree', 'shots': 5, 'goals': 1, 'pct': 0.2}, {'jersey_number': 17, 'player_name': 'sean', 'shots': 1, 'goals': 0, 'pct': 0.0}], 'status': 'tied'}, 'away': {'team_ID': 205, 'conference': 'big10', 'wins': 9, 'losses': 4, 'score': 9, 'players': [{'jersey_number': 9, 'player_name': 'julie', 'shots': 4, 'goals': 0, 'pct': 0.0}, {'jersey_number': 2, 'player_name': 'james', 'shots': 3, 'goals': 1, 'pct': 0.3333333333333333}, {'jersey_number': 16, 'player_name': 'jimmy', 'shots': 1, 'goals': 0, 'pct': 0.0}, {'jersey_number': 3, 'player_name': 'jane', 'shots': 1, 'goals': 0, 'pct': 0.0}, {'jersey_number': 15, 'player_name': 'jane', 'shots': 2, 'goals': 2, 'pct': 1.0}, {'jersey_number': 5, 'player_name': 'jimmy', 'shots': 1, 'goals': 1, 'pct': 1.0}, {'jersey_number': 1, 'player_name': 'jimmy', 'shots': 3, 'goals': 3, 'pct': 1.0}, {'jersey_number': 22, 'player_name': 'julie', 'shots': 1, 'goals': 0, 'pct': 0.0}, {'jersey_number': 17, 'player_name': 'james', 'shots': 3, 'goals': 1, 'pct': 0.3333333333333333}, {'jersey_number': 8, 'player_name': 'julie', 'shots': 2, 'goals': 1, 'pct': 0.5}], 'status': 'losing'}}\n"
     ]
    }
   ],
   "source": [
    "# Q9\n",
    "\n",
    "df_2.createOrReplaceTempView(\"gamestream\")\n",
    "\n",
    "sql_query = \"\"\"\n",
    "\n",
    "SELECT gs.team_ID, gs.jersey_number, COUNT(*) AS shots, SUM(gs.goals) AS goals, tg.team_goals\n",
    "FROM gamestream gs\n",
    "JOIN\n",
    "    (SELECT team_ID, SUM(goals) AS team_goals\n",
    "         FROM gamestream\n",
    "         WHERE team_ID > 0\n",
    "     GROUP BY team_ID) \n",
    "tg ON gs.team_ID = tg.team_ID\n",
    "\n",
    "WHERE gs.team_ID > 0\n",
    "GROUP BY gs.team_ID, gs.jersey_number, tg.team_goals\n",
    "ORDER BY gs.team_ID, gs.jersey_number\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(sql_query)\n",
    "\n",
    "\n",
    "from pyspark.sql import functions as func\n",
    "\n",
    "df_2.createOrReplaceTempView(\"gamestream\")\n",
    "\n",
    "latest_event_and_timestamp = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        MAX(event_id) AS latest_eventid, \n",
    "        MAX(timestamp) AS latest_timestamp\n",
    "    FROM gamestream\n",
    "    WHERE team_ID != 0\n",
    "\"\"\").collect()[0]\n",
    "\n",
    "latest_eventid = latest_event_and_timestamp['latest_eventid']\n",
    "latest_timestamp = latest_event_and_timestamp['latest_timestamp']\n",
    "\n",
    "result_2 = result.withColumn(\"latest_eventid\", func.lit(latest_eventid))\\\n",
    "                     .withColumn(\"latest_timestamp\", func.lit(latest_timestamp))\n",
    "\n",
    "\n",
    "players_df = spark.read.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"players\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .load()\n",
    "\n",
    "teams_df = spark.read.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"teams\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .load()\n",
    "\n",
    "result.createOrReplaceTempView(\"result\")\n",
    "players_df.createOrReplaceTempView(\"players\")\n",
    "teams_df.createOrReplaceTempView(\"teams\")\n",
    "\n",
    "df_3 = spark.sql(\"\"\"\n",
    "SELECT r.*, p.name as player_name, t.name as team_name, t.conference, t.wins, t.losses\n",
    "FROM result r\n",
    "LEFT JOIN players p ON p.teamid = r.team_ID AND r.jersey_number = p.number\n",
    "LEFT JOIN teams t ON r.team_ID = t.id\n",
    "\"\"\")\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "team_stats_agg = df_3.groupBy(\"team_ID\").agg(\n",
    "    F.first(\"conference\").alias(\"conference\"),\n",
    "    F.first(\"wins\").alias(\"wins\"),\n",
    "    F.first(\"losses\").alias(\"losses\"),\n",
    "    F.sum(\"goals\").alias(\"score\"),\n",
    "    F.collect_list(\n",
    "        F.struct(\n",
    "            \"jersey_number\", \n",
    "            \"player_name\", \n",
    "            \"shots\", \n",
    "            \"goals\",\n",
    "            F.when(F.col(\"shots\") > 0, F.col(\"goals\") / F.col(\"shots\")).otherwise(F.lit(0)).alias(\"pct\")\n",
    "        )\n",
    "    ).alias(\"players\")\n",
    ")\n",
    "\n",
    "# Calculate max score over each partition\n",
    "windowSpec = Window.partitionBy()\n",
    "team_stats_agg = team_stats_agg.withColumn(\"max_score\", F.max(\"score\").over(windowSpec))\n",
    "\n",
    "team_stats_agg = team_stats_agg.withColumn(\n",
    "    \"status\",\n",
    "    F.when(F.col(\"score\") == F.col(\"max_score\"), \"tied\").otherwise(\n",
    "        F.when(F.col(\"score\") < F.col(\"max_score\"), \"losing\").otherwise(\"winning\")\n",
    "    )\n",
    ").drop(\"max_score\")\n",
    "\n",
    "# Filter for specific teams\n",
    "home_team_stats = team_stats_agg.filter(F.col(\"team_ID\") == 101)\n",
    "away_team_stats = team_stats_agg.filter(F.col(\"team_ID\") == 205)\n",
    "\n",
    "import json\n",
    "\n",
    "home_dict = json.loads(home_json)\n",
    "away_dict = json.loads(away_json)\n",
    "\n",
    "\n",
    "box_score_document = {\n",
    "    \"_id\": latest_eventid,\n",
    "    \"timestamp\": latest_timestamp,\n",
    "    \"home\": home_dict,\n",
    "    \"away\": away_dict\n",
    "}\n",
    "\n",
    "print(box_score_document) \n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48e06ed5-3f98-4663-8819-dfb03c15fb58",
   "metadata": {},
   "source": [
    "#10Q\n",
    "SELECT * FROM mongo.sidearm.boxscores where _id = (SELECT MAX(_id) FROM mongo.sidearm.boxscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "21f247ee-6af5-4f3e-acc9-24fbd6f02942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------+----+------+------------+--------------+\n",
      "| id|         name|conference|wins|losses|updated_wins|updated_losses|\n",
      "+---+-------------+----------+----+------+------------+--------------+\n",
      "|101|     syracuse|       acc|  11|     2|          11|             2|\n",
      "|205|johns hopkins|     big10|   9|     4|           9|             5|\n",
      "+---+-------------+----------+----+------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q11\n",
    "# Extracting the status of both teams from the box score JSON document\n",
    "home_status = box_score_document[\"home\"][\"status\"]\n",
    "away_status = box_score_document[\"away\"][\"status\"]\n",
    "\n",
    "def modify_team_records(teams_df, team_id_val, team_status):\n",
    "    updated_teams_df = teams_df.withColumn(\n",
    "        'updated_wins', \n",
    "        F.when((F.col('id') == team_id_val) & (F.lit(team_status) == 'winning'), F.col('wins') + 1)\n",
    "        .otherwise(F.col('wins'))\n",
    "    ).withColumn(\n",
    "        'updated_losses', \n",
    "        F.when((F.col('id') == team_id_val) & (F.lit(team_status) == 'losing'), F.col('losses') + 1)\n",
    "        .otherwise(F.col('losses'))\n",
    "    )\n",
    "    return updated_teams_df\n",
    "\n",
    "# Updating team statistics based on the status\n",
    "df_teams_updated = modify_team_records(teams_df, 101, home_status)\n",
    "df_teams_updated = modify_team_records(teams_df, 205, away_status)\n",
    "\n",
    "df_teams_updated.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "473e48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q12\n",
    "df_teams_updated.write.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"teams2\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b963d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-----+-----+------+-------+-------------+-----+-----+----------+-----------+-------------+----------+----+------+\n",
      "| id|  name|number|shots|goals|teamid|team_ID|jersey_number|shots|goals|team_goals|player_name|    team_name|conference|wins|losses|\n",
      "+---+------+------+-----+-----+------+-------+-------------+-----+-----+----------+-----------+-------------+----------+----+------+\n",
      "| 10| swede|    10|   90|   50|   101|    101|           10|    3|    1|        14|      swede|     syracuse|       acc|  11|     2|\n",
      "|  7|   sol|     9|   52|   20|   101|    101|            9|    4|    0|        14|        sol|     syracuse|       acc|  11|     2|\n",
      "| 20| julie|    22|   83|   19|   205|    205|           22|    1|    0|         9|      julie|johns hopkins|     big10|   9|     4|\n",
      "|  3| steve|     2|   60|   20|   101|    101|            2|    7|    2|        14|      steve|     syracuse|       acc|  11|     2|\n",
      "| 14|  jane|    15|   82|   46|   205|    205|           15|    2|    2|         9|       jane|johns hopkins|     big10|   9|     4|\n",
      "|  2| sarah|     1|   85|   34|   101|    101|            1|    7|    6|        14|      sarah|     syracuse|       acc|  11|     2|\n",
      "|  9|shelly|    15|   10|    2|   101|    101|           15|    3|    1|        14|     shelly|     syracuse|       acc|  11|     2|\n",
      "| 18|  jane|     3|   91|   40|   205|    205|            3|    1|    0|         9|       jane|johns hopkins|     big10|   9|     4|\n",
      "| 12| julie|     9|   10|    0|   205|    205|            9|    4|    0|         9|      julie|johns hopkins|     big10|   9|     4|\n",
      "| 15| jimmy|    16|   42|   30|   205|    205|           16|    1|    0|         9|      jimmy|johns hopkins|     big10|   9|     4|\n",
      "| 19| jimmy|     5|   78|   22|   205|    205|            5|    1|    1|         9|      jimmy|johns hopkins|     big10|   9|     4|\n",
      "|  5|  sean|    17|   26|    9|   101|    101|           17|    1|    0|        14|       sean|     syracuse|       acc|  11|     2|\n",
      "| 11| jimmy|     1|  100|   50|   205|    205|            1|    3|    3|         9|      jimmy|johns hopkins|     big10|   9|     4|\n",
      "|  1|   sam|     6|   56|   23|   101|    101|            6|    4|    2|        14|        sam|     syracuse|       acc|  11|     2|\n",
      "|  4| stone|    13|   33|   10|   101|    101|           13|    5|    1|        14|      stone|     syracuse|       acc|  11|     2|\n",
      "| 13| james|     2|   45|   15|   205|    205|            2|    3|    1|         9|      james|johns hopkins|     big10|   9|     4|\n",
      "|  6|   sly|     8|   78|   15|   101|    101|            8|    3|    0|        14|        sly|     syracuse|       acc|  11|     2|\n",
      "|  8| shree|     4|   20|    4|   101|    101|            4|    5|    1|        14|      shree|     syracuse|       acc|  11|     2|\n",
      "| 17| james|    17|   40|   14|   205|    205|           17|    3|    1|         9|      james|johns hopkins|     big10|   9|     4|\n",
      "| 16| julie|     8|   67|   32|   205|    205|            8|    2|    1|         9|      julie|johns hopkins|     big10|   9|     4|\n",
      "+---+------+------+-----+-----+------+-------+-------------+-----+-----+----------+-----------+-------------+----------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q13\n",
    "new_stats = players_df.alias('players').join(\n",
    "    df_3.alias('new_stats'),\n",
    "    (players_df['name'] == df_3['player_name']) & \n",
    "    (players_df['number'] == df_3['jersey_number']),\n",
    "    'left'\n",
    ")\n",
    "\n",
    "new_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3a5594d8-96ec-4aed-a6bf-cfafa9fd9d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-----+-----+------+\n",
      "| id|  name|number|shots|goals|teamid|\n",
      "+---+------+------+-----+-----+------+\n",
      "| 10| swede|    10|   93|   51|   101|\n",
      "|  7|   sol|     9|   56|   20|   101|\n",
      "| 20| julie|    22|   84|   19|   205|\n",
      "|  3| steve|     2|   67|   22|   101|\n",
      "| 14|  jane|    15|   84|   48|   205|\n",
      "|  2| sarah|     1|   92|   40|   101|\n",
      "|  9|shelly|    15|   13|    3|   101|\n",
      "| 18|  jane|     3|   92|   40|   205|\n",
      "| 12| julie|     9|   14|    0|   205|\n",
      "| 15| jimmy|    16|   43|   30|   205|\n",
      "| 19| jimmy|     5|   79|   23|   205|\n",
      "|  5|  sean|    17|   27|    9|   101|\n",
      "| 11| jimmy|     1|  103|   53|   205|\n",
      "|  1|   sam|     6|   60|   25|   101|\n",
      "|  4| stone|    13|   38|   11|   101|\n",
      "| 13| james|     2|   48|   16|   205|\n",
      "|  6|   sly|     8|   81|   15|   101|\n",
      "|  8| shree|     4|   25|    5|   101|\n",
      "| 17| james|    17|   43|   15|   205|\n",
      "| 16| julie|     8|   69|   33|   205|\n",
      "+---+------+------+-----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_stats = new_stats.select('players.id', 'players.name', 'players.number',\n",
    "    (F.col('players.shots') + F.coalesce(F.col('new_stats.shots'), F.lit(0))).alias('shots'),\n",
    "    (F.col('players.goals') + F.coalesce(F.col('new_stats.goals'), F.lit(0))).alias('goals'),'players.teamid')\n",
    "new_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a048e59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Q14\n",
    "new_stats.write.format(\"com.microsoft.sqlserver.jdbc.spark\") \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .option(\"url\", mssql_url) \\\n",
    "    .option(\"dbtable\", \"players2\") \\\n",
    "    .option(\"user\", mssql_user) \\\n",
    "    .option(\"password\", mssql_pw) \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d369657-e1ef-4b0e-bff1-293784ab6b5b",
   "metadata": {},
   "source": [
    "# Q15\n",
    "SELECT t.name, t.wins, t.losses, p.name, p.shots, p.goals\n",
    "FROM players2 p\n",
    "join teams2 t on p.teamid = t.id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
